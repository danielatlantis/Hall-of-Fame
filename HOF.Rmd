---
title: "Hall of Fame Expectancy"
output: pdf_document
author: "Daniel Antantis"
---

```{r}
library(tidyverse)
library(rvest)
library(dplyr)
library(MASS)
library(glmnet)
```

**Read in raw player data**
```{r}
hit_data = read.csv("~/Documents/MLB Project/allhitters.csv")
head(hit_data)
```
**Read in Hall of Fame data and filter for only hitters by at-bats (AB)**
```{r}
url = "https://www.baseball-reference.com/awards/hof_batting.shtml"
tbl = url %>% 
  read_html() %>% 
  html_nodes('table') %>% 
  html_table()
hof = data.frame(tbl)
hof = hof %>% filter(AB > 3000)
```

**Filter for players eligible for HOF**
```{r}
hof_eligible = hit_data %>% 
  na.omit() %>% 
  group_by(name) %>% 
  filter(AB > 200) %>% 
  summarise(
    Retirement_Year = max(Year),
    AB = sum(AB),
    HR = sum(HR),
    RBI = sum(RBI),
    H = sum(H),
    BA = mean(BA),
    OBP = mean(OBP),
    SB = sum(SB),
    BB = sum(BB),
    IBB = sum(IBB),
    SLG = mean(SLG),
    OPS = mean(OPS),
    MVP = sum(ifelse(grepl("MVP-1,", Awards, fixed = TRUE), 1, 0)),
    All_star = sum(ifelse(grepl("AS", Awards, fixed = TRUE), 1, 0)),
    Gold_glove = sum(ifelse(grepl("GG", Awards, fixed = TRUE), 1, 0)),
    Silver_slugger = sum(ifelse(grepl("SS", Awards, fixed = TRUE), 1, 0))
  ) %>% 
  filter(Retirement_Year < 2016)
View(hof_eligible)
```

**Merge dataframes**
```{r}
hof_both = data.frame(hof_eligible$name[hof_eligible$name %in% hof$Name])
hof_both = hof_both %>% 
  summarise(name = hof_eligible.name.hof_eligible.name..in..hof.Name.)
hof_both$hof = 1
View(hof_both)
```

**Merge players with their stats (excluding players banned from HOF)**
```{r}
raw_data = hof_eligible %>% 
  left_join(hof_both, by = "name") 
raw_data[is.na(raw_data)] = 0
raw_data$ISO = raw_data$SLG - raw_data$BA
model_data = hof_eligible %>% 
  left_join(hof_both, by = "name") %>% 
  filter(!(name == "Barry Bonds" | name == "Pete Rose" | name == "Mark McGwire"))
model_data[is.na(model_data)] = 0
model_data$ISO = model_data$SLG - model_data$BA
View(model_data)
```

**Split into training and testing sets**
```{r}
attach(model_data)
sample_size <- floor(0.8 * nrow(model_data))
set.seed(111)
train <- sample(seq_len(nrow(model_data)), size = sample_size)
model_train = model_data[train,]
model_test = model_data[-train,]
```

**Linear Model**
```{r}
LDA.fit = lda(hof ~ HR + AB + BA + OPS + BB + MVP + All_star + Gold_glove + Silver_slugger, data = model_train, subset = train)
LDA.pred = predict(LDA.fit, model_test)
mean(LDA.pred$class != model_test$hof)
```

```{r}
GLM.fit = glm(hof ~ HR + AB + BA + OPS + BB + ISO + MVP + All_star + Gold_glove + Silver_slugger, data = model_train, family = binomial, subset = train)
GLM.probs = predict(GLM.fit, model_test, type = "response")
GLM.pred = rep(0, length(GLM.probs))
GLM.pred[GLM.probs > 0.5] = 1
mean(GLM.pred != model_test$hof)
```


```{r}
QDA.fit = qda(hof ~ HR + AB + BA + OPS + BB + MVP + All_star + Gold_glove + Silver_slugger, data = model_train, subset = train)
QDA.pred = predict(QDA.fit, model_test)
mean(QDA.pred$class != model_test$hof)
```

```{r}
train.x = model.matrix(hof ~ HR + AB + BA + OPS + BB + MVP + All_star + Gold_glove + Silver_slugger, data = model_train)
train.hof = model_train$hof
test.x = model.matrix(hof ~ HR + AB + BA + OPS + BB + MVP + All_star + Gold_glove + Silver_slugger, data = model_test)
test.hof = model_test$hof

ridge.fit = cv.glmnet(train.x, train.hof, alpha = 0)
ridge.lambda = ridge.fit$lambda.min

ridge.probs = predict(ridge.fit, s = ridge.lambda, newx = test.x)
ridge.pred = rep(0, length(ridge.probs))
ridge.pred[ridge.probs > 0.5] = 1
mean(ridge.pred != model_test$hof)
```

```{r}
ridge.coef = predict(ridge.fit, type = "coefficients", s = ridge.lambda)
ridge.coef
```

**Which players were classified incorrectly**
```{r}
incorrect_name = ifelse(GLM.pred != model_test$hof, model_test$name, NA)
incorrect_pred = ifelse(GLM.pred != model_test$hof, ridge.pred, NA)
incorrect = data.frame(incorrect_name, incorrect_pred)
incorrect = incorrect %>% na.omit()
View(incorrect)
```

**Test model generalization**
```{r}
total.probs = predict(GLM.fit, model_data, type = "response")
total.pred = rep(0, length(total.probs))
total.pred[total.probs > 0.5] = 1
name = ifelse(total.pred != model_data$hof, model_data$name, NA)
pred = ifelse(total.pred != model_data$hof, total.pred, NA)
prob = ifelse(total.pred != model_data$hof, round(total.probs,3), NA)
end1 = data.frame(name, pred, prob)
end1 = end1 %>% na.omit()
end1_data = end1 %>% left_join(model_data, by = "name") %>% mutate_all(~replace(., is.na(.), 0))
View(end1_data)
nrow(end1)
name = ifelse(total.pred == 1 & model_data$hof == 1, model_data$name, NA)
pred = ifelse(total.pred == 1 & model_data$hof == 1, total.pred, NA)
prob = ifelse(total.pred == 1 & model_data$hof == 1, round(total.probs,3), NA)
end2 = data.frame(name, pred, prob)
end2 = end2 %>% na.omit()
end2_data = end2 %>% left_join(model_data, by = "name") %>% mutate_all(~replace(., is.na(.), 0))
View(end2_data)
nrow(end2)
```


**GLM Deep Dive**
```{r}
GLM.fit$coefficients
summary(GLM.fit)
```
**Would the model incorrectly predict players who would be in HOF if not banned**
```{r}
banned  = raw_data %>% 
  filter(name == "Barry Bonds" | name == "Mark McGwire" | name == "Pete Rose")
View(banned)
GLM.probs = predict(GLM.fit, banned, type = "response")
GLM.pred = rep(0, length(GLM.probs))
GLM.pred[GLM.probs > 0.5] = 1
incorrect_ban_name = ifelse(GLM.pred != banned$hof, banned$name, NA)
incorrect_ban_pred = ifelse(GLM.pred != banned$hof, GLM.pred, NA)
incorrect_ban_prob = ifelse(GLM.pred != banned$hof, GLM.probs, NA)
incorrect_ban = data.frame(incorrect_ban_name, incorrect_ban_pred, incorrect_ban_prob)
incorrect_ban = incorrect_ban %>% na.omit()
View(incorrect_ban)
```



